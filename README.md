# OptimaLLM

**Attention! Please replace YOUR_OPENAI_API_KEY with your personal valid OpenAI API key.**

Requirements: `pip install httpx` or `pip3 install httpx`

The official implementation of the paper *Refining the Responses of LLMs by Themselves*. In this paper, we propose a simple yet efficient approach based on prompt engineering that leverages the large language model itself to optimize its answers without relying on auxiliary models. We introduce an iterative self-evaluating optimization mechanism, with the potential for improved output quality as iterations progress, removing the need for manual intervention. The experiment's findings indicate that utilizing our response refinement framework on the GPT-3.5 model yields results that are on par with, or even surpass, those generated by the cutting-edge GPT-4 model. Detailed implementation strategies and illustrative examples are provided to demonstrate the superiority of our proposed solution.

<img width="645" alt="image" src="https://user-images.githubusercontent.com/20149275/236629683-e4fd0122-6f95-414f-9e50-e8071aa01df2.png">

![Figure3  Answers of the five selected questions generated by the original GPT-3 5-Turbo, the original GPT-4, and the refined GPT-3 5](https://user-images.githubusercontent.com/20149275/236629603-d96d4496-6130-4b0e-83c0-ac5dc3c973ad.png)

